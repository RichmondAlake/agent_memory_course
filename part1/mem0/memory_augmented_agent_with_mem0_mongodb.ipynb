{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "04323d1d",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github.com/RichmondAlake/agent_memory_course/blob/main/mem0/memory_augmented_agent_with_mem0_mongodb.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e1ccaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU mem0ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b701237",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "CURRENT_USER_ID = \"user-123\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9bab6374",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Function to securely get and set environment variables\n",
    "def set_env_securely(var_name, prompt):\n",
    "    value = getpass.getpass(prompt)\n",
    "    os.environ[var_name] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "207f4977",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_env_securely(\"OPENAI_API_KEY\", \"Enter your OPENAI_API_KEY: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a1efef",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_env_securely(\"MONGODB_URI\", \"Enter your MongoDB URI: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8a7f177",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"vector_store\": {\n",
    "        \"provider\": \"mongodb\",\n",
    "        \"config\": {\n",
    "            \"db_name\": \"mem0_agent_memory\",\n",
    "            \"collection_name\": \"extracted_memories\",\n",
    "            \"mongo_uri\": os.environ[\"MONGODB_URI\"]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "semantic_memory_config = {\n",
    "    \"vector_store\": {\n",
    "        \"provider\": \"mongodb\",\n",
    "        \"config\": {\n",
    "            \"db_name\": \"mem0_agent_memory\",\n",
    "            \"collection_name\": \"semantic_memory\",\n",
    "            \"mongo_uri\": os.environ[\"MONGODB_URI\"]\n",
    "        }\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "805e0f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mem0.vector_stores.mongodb:Search index 'extracted_memories_vector_index' already exists in collection 'extracted_memories'.\n",
      "INFO:mem0.vector_stores.mongodb:Search index 'mem0migrations_vector_index' already exists in collection 'mem0migrations'.\n",
      "INFO:mem0.vector_stores.mongodb:Retrieved document with ID '2a50db03-70cb-4ce8-85ce-cf68cf30343e'.\n",
      "INFO:mem0.vector_stores.mongodb:MongoClient connection closed.\n",
      "INFO:mem0.vector_stores.mongodb:MongoClient connection closed.\n",
      "INFO:mem0.vector_stores.mongodb:Search index 'semantic_memory_vector_index' already exists in collection 'semantic_memory'.\n",
      "INFO:mem0.vector_stores.mongodb:Search index 'mem0migrations_vector_index' already exists in collection 'mem0migrations'.\n",
      "INFO:mem0.vector_stores.mongodb:Retrieved document with ID '2a50db03-70cb-4ce8-85ce-cf68cf30343e'.\n",
      "INFO:mem0.vector_stores.mongodb:MongoClient connection closed.\n",
      "INFO:mem0.vector_stores.mongodb:MongoClient connection closed.\n"
     ]
    }
   ],
   "source": [
    "from mem0 import Memory\n",
    "memory = Memory.from_config(config)\n",
    "semantic_memory = Memory.from_config(semantic_memory_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9004e865",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dce7b40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from typing import Optional, Dict\n",
    "\n",
    "openai_client = OpenAI()\n",
    "\n",
    "def patched_search_vector_store(self, query, filters, limit, threshold: Optional[float] = None):\n",
    "    \"\"\"\n",
    "    Patched version of _search_vector_store that uses the correct MongoDB parameter name.\n",
    "    \n",
    "    This fixes the TypeError: MongoDB.search() got an unexpected keyword argument 'vectors'\n",
    "    by using 'query_vector' instead of 'vectors' to match the actual MongoDB implementation.\n",
    "    \"\"\"\n",
    "    # Generate embeddings for the query\n",
    "    embeddings = self.embedding_model.embed(query, \"search\")\n",
    "    \n",
    "    # Call MongoDB search with correct parameter name: query_vector instead of vectors\n",
    "    memories = self.vector_store.search(query=query, query_vector=embeddings, limit=limit, filters=filters)\n",
    "    \n",
    "    # Process the results to match expected format\n",
    "    promoted_payload_keys = [\n",
    "        \"user_id\",\n",
    "        \"agent_id\", \n",
    "        \"run_id\",\n",
    "        \"actor_id\",\n",
    "        \"role\",\n",
    "    ]\n",
    "\n",
    "    core_and_promoted_keys = {\"data\", \"hash\", \"created_at\", \"updated_at\", \"id\", *promoted_payload_keys}\n",
    "\n",
    "    # Apply threshold filtering if specified\n",
    "    if threshold is not None:\n",
    "        filtered_memories = []\n",
    "        for memory_item in memories:\n",
    "            if hasattr(memory_item, 'score') and memory_item.score >= threshold:\n",
    "                filtered_memories.append(memory_item)\n",
    "        memories = filtered_memories\n",
    "\n",
    "    # Serialize memories to expected format\n",
    "    serialized_memories = []\n",
    "    for memory_item in memories:\n",
    "        serialized_memory = {}\n",
    "        \n",
    "        # Handle the core fields\n",
    "        for key in core_and_promoted_keys:\n",
    "            if key == \"data\":\n",
    "                # The actual memory content is in the payload\n",
    "                serialized_memory[key] = getattr(memory_item, 'payload', {}).get('data', None)\n",
    "            else:\n",
    "                serialized_memory[key] = getattr(memory_item, key, None)\n",
    "\n",
    "        # Add score and memory content\n",
    "        serialized_memory[\"score\"] = getattr(memory_item, \"score\", None)\n",
    "        serialized_memory[\"memory\"] = getattr(memory_item, 'payload', {}).get('data', '')\n",
    "        serialized_memory[\"metadata\"] = getattr(memory_item, 'payload', {}).get('metadata', {})\n",
    "\n",
    "        # Add promoted payload keys\n",
    "        payload = getattr(memory_item, 'payload', {})\n",
    "        for key in promoted_payload_keys:\n",
    "            value = payload.get(key, None)\n",
    "            if value is not None:\n",
    "                serialized_memory[key] = value\n",
    "\n",
    "        serialized_memories.append(serialized_memory)\n",
    "\n",
    "    return serialized_memories\n",
    "\n",
    "def create_patched_add_to_vector_store(original_method):\n",
    "    \"\"\"\n",
    "    Factory function to create a patched _add_to_vector_store method.\n",
    "    This ensures each memory instance gets its own reference to the original method.\n",
    "    \"\"\"\n",
    "    def patched_add_to_vector_store(self, messages, metadata, filters, infer):\n",
    "        \"\"\"\n",
    "        Patched version of _add_to_vector_store that fixes the MongoDB search parameter issue.\n",
    "        \n",
    "        This method is called during memory.add() operations and also uses the incorrect 'vectors' parameter.\n",
    "        \"\"\"\n",
    "        # Import the logger from the original module\n",
    "        import logging\n",
    "        logger = logging.getLogger(__name__)\n",
    "        \n",
    "        # Get the ACTUAL MongoDB vector store search method (not our patched version)\n",
    "        mongodb_vector_store = self.vector_store\n",
    "        \n",
    "        # Get the original MongoDB search method directly\n",
    "        original_mongodb_search = mongodb_vector_store.__class__.search\n",
    "        \n",
    "        def patched_vector_store_search(self_vs, query, vectors, limit, filters):\n",
    "            # Fix the parameter name: vectors -> query_vector\n",
    "            return original_mongodb_search(self_vs, query=query, query_vector=vectors, limit=limit, filters=filters)\n",
    "        \n",
    "        # Temporarily patch the vector store search method\n",
    "        original_vector_store_search = mongodb_vector_store.search\n",
    "        mongodb_vector_store.search = patched_vector_store_search.__get__(mongodb_vector_store, mongodb_vector_store.__class__)\n",
    "        \n",
    "        try:\n",
    "            # Call the original _add_to_vector_store method as a bound method\n",
    "            result = original_method.__get__(self, type(self))(messages, metadata, filters, infer)\n",
    "            return result\n",
    "        finally:\n",
    "            # Restore the original vector store search method\n",
    "            mongodb_vector_store.search = original_vector_store_search\n",
    "    \n",
    "    return patched_add_to_vector_store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a4d047f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîß MongoDB search and add methods patched successfully for both memory instances!\n"
     ]
    }
   ],
   "source": [
    "# Apply the monkey patches at both class and instance level\n",
    "from mem0.memory.main import Memory\n",
    "\n",
    "# Store original methods for each instance BEFORE patching\n",
    "memory_original_search = memory._search_vector_store\n",
    "memory_original_add = memory._add_to_vector_store\n",
    "semantic_memory_original_search = semantic_memory._search_vector_store\n",
    "semantic_memory_original_add = semantic_memory._add_to_vector_store\n",
    "\n",
    "# Store original class methods before any patching\n",
    "original_class_search = Memory._search_vector_store\n",
    "original_class_add = Memory._add_to_vector_store\n",
    "\n",
    "# Apply class-level patches (affects new instances)\n",
    "Memory._search_vector_store = patched_search_vector_store\n",
    "Memory._add_to_vector_store = create_patched_add_to_vector_store(original_class_add)\n",
    "\n",
    "# Create instance-specific patched add methods\n",
    "memory_patched_add = create_patched_add_to_vector_store(memory_original_add)\n",
    "semantic_memory_patched_add = create_patched_add_to_vector_store(semantic_memory_original_add)\n",
    "\n",
    "# Apply patches to existing instances\n",
    "memory._search_vector_store = patched_search_vector_store.__get__(memory, memory.__class__)\n",
    "memory._add_to_vector_store = memory_patched_add.__get__(memory, memory.__class__)\n",
    "\n",
    "semantic_memory._search_vector_store = patched_search_vector_store.__get__(semantic_memory, semantic_memory.__class__)\n",
    "semantic_memory._add_to_vector_store = semantic_memory_patched_add.__get__(semantic_memory, semantic_memory.__class__)\n",
    "\n",
    "print(\"üîß MongoDB search and add methods patched successfully for both memory instances!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd50a39",
   "metadata": {},
   "source": [
    "## Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b20bfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading PDF from https://arxiv.org/pdf/2404.13501...\n",
      "Loading PDF with LangChain...\n",
      "Chunking text...\n",
      "Successfully created 197 chunks\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Method 1: Add the project root directory to Python path\n",
    "project_root = \"/Users/richmondalake/Desktop/Projects/open_source/agent_memory_course\"\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utilities.pdf_chunker import ingest_pdf_and_chunk\n",
    "\n",
    "url = \"https://arxiv.org/pdf/2404.13501\"\n",
    "\n",
    "# Ingest and chunk the PDF\n",
    "chunks = ingest_pdf_and_chunk(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "260e2af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ingest chunks into semantic memory one by one to avoid timeout issues\n",
    "print(f\"üìÑ Ingesting {len(chunks)} chunks into semantic memory...\")\n",
    "\n",
    "successful_ingestions = 0\n",
    "failed_ingestions = 0\n",
    "\n",
    "for i, chunk in enumerate(chunks):\n",
    "    try:\n",
    "        # Process each chunk individually\n",
    "        chunk_content = chunk[\"value\"][\"content\"]\n",
    "        \n",
    "        # Skip very short chunks (less than 50 characters)\n",
    "        if len(chunk_content.strip()) < 50:\n",
    "            continue\n",
    "            \n",
    "        # Create a single message for this chunk\n",
    "        message = {\"role\": \"user\", \"content\": chunk_content}\n",
    "        \n",
    "        # Add to semantic memory\n",
    "        result = semantic_memory.add([message], user_id=CURRENT_USER_ID, infer=False)\n",
    "        successful_ingestions += 1\n",
    "        \n",
    "        if (i + 1) % 10 == 0:  # Progress update every 10 chunks\n",
    "            print(f\"   Processed {i + 1}/{len(chunks)} chunks...\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ùå Failed to ingest chunk {i}: {str(e)[:100]}...\")\n",
    "        failed_ingestions += 1\n",
    "        continue\n",
    "\n",
    "print(f\"‚úÖ Ingestion complete!\")\n",
    "print(f\"   - Successfully ingested: {successful_ingestions} chunks\")\n",
    "print(f\"   - Failed: {failed_ingestions} chunks\")\n",
    "print(f\"   - Total processed: {successful_ingestions + failed_ingestions}/{len(chunks)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2a13ec7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chat with AI (type 'exit' to quit)\n",
      "This AI has memory and can remember your conversation!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mem0.vector_stores.mongodb:Retrieved document with ID '2a50db03-70cb-4ce8-85ce-cf68cf30343e'.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:mem0.vector_stores.mongodb:Vector search completed. Found 0 documents.\n",
      "INFO:mem0.vector_stores.mongodb:Retrieved document with ID '2a50db03-70cb-4ce8-85ce-cf68cf30343e'.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:mem0.vector_stores.mongodb:Vector search completed. Found 3 documents.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memories:\n",
      "No relevant memories found.\n",
      "Semantic Memories:\n",
      "- You may like this blue dress. It is \n",
      "of good quality and great price.\n",
      "Would you like to buy a \n",
      "waistband for your dress?\n",
      "Great! I like this bule one. \n",
      "I will buy it for the party.\n",
      "Medicine\n",
      "David, a 38-year-old male with a history of allergies and sinus \n",
      "infections, has a family history of diabetes and hypertension. As \n",
      "a smoker of about one pack a day and an occasional drinker, \n",
      "his lifestyle choices may contribute to his health risks. After \n",
      "traveling to a tropical country where mosquito-borne illnesses \n",
      "are prevalent, he has experienced symptoms such as mild \n",
      "fatigue, headache, and muscle aches for the past week. \n",
      "For three days, I‚Äôve had a \n",
      "fever ranging from \n",
      "100.5¬∞F to 102¬∞F, a rash \n",
      "on my limbs, joint pain \n",
      "and swelling, especially \n",
      "in my hands, episodes of \n",
      "diarrhea, abdominal pain, \n",
      "and nausea, leading to a \n",
      "loss of appetite.\n",
      "The patient‚Äòs travel history and \n",
      "symptoms suggest dengue fever, \n",
      "a mosquito-transmitted illness.\n",
      "Finance\n",
      "- at https://github.com/nuster1128/LLM_Agent_Memory_Survey.\n",
      "Personal Assistant\n",
      "Please help me to explain \n",
      "‚ÄúLLM-based agent‚Äù.\n",
      "A LLM-based agent is a \n",
      "type of artificial ‚Ä¶‚Ä¶\n",
      "In which scenarios does it \n",
      "have applications?\n",
      "Personal assistant, game,\n",
      "code generation, ‚Ä¶‚Ä¶\n",
      "(Knowledge) According to the previous works, large \n",
      "language model based agents refer to artificial ‚Ä¶‚Ä¶\n",
      "(Context) The current topic is LLM-based agent. ‚ÄúIt‚Äù \n",
      "refers to LLM-based agents in this conversation.\n",
      "Social Simulation\n",
      " I'm a compassionate physician \n",
      "specializing in cardiology, \n",
      "committed to improving patients' \n",
      "heart health and well-being.\n",
      "I'm a skilled nurse dedicated to \n",
      "patient care, ensuring comfort and \n",
      "supporting health with empathy \n",
      "and expertise.\n",
      "Role-playing\n",
      "I' m a Smurf, and \n",
      "Smurfs are us!\n",
      "Have you ever had \n",
      "a dream?\n",
      "Magic is all \n",
      "around the us!\n",
      "Jarvis, we must \n",
      "first learn to run!\n",
      "Wubalubadu.\n",
      "Bdub Wuckoop.\n",
      "I' m Batman, the \n",
      "lights of city.\n",
      "[Iron Man] My name is Iron Man, \n",
      "also known as Tony Stark. I am\n",
      "- [140] Dacheng Li, Rulin Shao, Anze Xie, Ying Sheng, Lianmin Zheng, Joseph Gonzalez, Ion Stoica,\n",
      "Xuezhe Ma, and Hao Zhang. How long can context length of open-source llms truly promise?\n",
      "In NeurIPS 2023 Workshop on Instruction Tuning and Instruction Following, 2023.\n",
      "[141] Mohit Shridhar, Xingdi Yuan, Marc-Alexandre C√¥t√©, Yonatan Bisk, Adam Trischler, and\n",
      "Matthew Hausknecht. Alfworld: Aligning text and embodied environments for interactive\n",
      "learning. arXiv preprint arXiv:2010.03768, 2020.\n",
      "[142] YunDa Tsai, Mingjie Liu, and Haoxing Ren. Rtlfixer: Automatically fixing rtl syntax errors\n",
      "with large language models. arXiv preprint arXiv:2311.16543, 2023.\n",
      "[143] Cheng Li, Ziang Leng, Chenxi Yan, Junyi Shen, Hao Wang, Weishi Mi, Yaying Fei, Xiaoyang\n",
      "Feng, Song Yan, HaoSheng Wang, et al. Chatharuhi: Reviving anime character in reality via\n",
      "large language model. arXiv preprint arXiv:2308.09597, 2023.\n",
      "[144] Dake Chen, Hanbin Wang, Yunhao Huo, Yuzhao Li, and Haoyang Zhang. Gamegpt: Multi-\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:mem0.memory.main:Total existing memories: 0\n",
      "INFO:mem0.vector_stores.mongodb:Retrieved document with ID '2a50db03-70cb-4ce8-85ce-cf68cf30343e'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: Hello! How can I assist you today?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mem0.vector_stores.mongodb:Retrieved document with ID '2a50db03-70cb-4ce8-85ce-cf68cf30343e'.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:mem0.vector_stores.mongodb:Vector search completed. Found 0 documents.\n",
      "INFO:mem0.vector_stores.mongodb:Retrieved document with ID '2a50db03-70cb-4ce8-85ce-cf68cf30343e'.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:mem0.vector_stores.mongodb:Vector search completed. Found 3 documents.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memories:\n",
      "No relevant memories found.\n",
      "Semantic Memories:\n",
      "- the Summer Palace as the destinations. Environment (Alice): Well done!\n",
      "[Step 3] Agent: Now, I need to arrange the visiting order for Alice. According to the information\n",
      "above, I recommend visiting the Summer Palace after she arrives in Beijing because it is suitable to\n",
      "spend a whole afternoon there and watch the sunset. Then, she can go to the Forbidden City the next\n",
      "day, which would give her plenty of time. Finally, she can return to Shanghai on the third day and\n",
      "take a rest. Environment (Alice): I love this plan. Thanks!\n",
      "8\n",
      "- In previous works, Character-LLM [105] focuses on the role-play circumstance. It utilizes supervised\n",
      "fine-tuning strategies with role-related data ( e.g., experiences), to endow agents with the specific\n",
      "traits and characteristics of the role. Huatuo [ 107] intends to empower agents with professional\n",
      "ability in the biomedical domain. It tries to fine-tune Llama [127] on Chinese medical knowledge\n",
      "bases. Besides, in order to create artificial doctors, DoctorGLM [ 129] fine-tunes ChatGLM [130]\n",
      "with LoRA [131], and Radiology-GPT [ 132] improves domain knowledge on radiology analysis\n",
      "by supervised fine-tuning on an annotated radiology dataset. Moreover, InvestLM [ 113] collects\n",
      "investment data and fine-tunes it to improve domain-specific abilities on financial investment.\n",
      "The fine-tuning methods can effectively bridge the gap between general agents and specialized\n",
      "agents. It improves the capability of agents on the tasks that require high accuracy and reliability on\n",
      "- For task (B), the trial is:\n",
      "[Step 1] Agent: According to my previous experiences of movie recommendations for Alice, she\n",
      "prefers to start watching movies at 9:00 PM, because she has finished work by then. I should ask\n",
      "Alice if she is available at that time. Environment (Alice): Of course, it is a nice time!\n",
      "[Step 2] Agent: Now, I need to find some movies that Alice has marked \"want to watch\" on Netflix.\n",
      "Environment (Netflix): Alice‚Äôs want to watch: Interstellar, Planet Terror and Candle in the Tomb.\n",
      "[Step 3] Agent: Since Alice never watches horror movies at night,Interstellar would be more suitable\n",
      "for her. Now, I need to confirm with Alice about the movie. Environment (Alice): Great! I like it!\n",
      "3.2 Narrow Definition of the Agent Memory\n",
      "In a narrow sense, the memory of the agent is only relevant to the historical information within\n",
      "the same trial. Formally, for a given task, the historical information of the trial before step t is\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:mem0.vector_stores.mongodb:Vector search completed. Found 0 documents.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:mem0.vector_stores.mongodb:Vector search completed. Found 0 documents.\n",
      "INFO:mem0.memory.main:Total existing memories: 0\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:mem0.memory.main:{'id': '0', 'text': 'Likes to drink tea', 'event': 'ADD'}\n",
      "INFO:mem0.vector_stores.mongodb:Inserting 1 vectors into collection 'extracted_memories'.\n",
      "INFO:mem0.vector_stores.mongodb:Inserted 1 documents into 'extracted_memories'.\n",
      "INFO:mem0.vector_stores.mongodb:Retrieved document with ID '2a50db03-70cb-4ce8-85ce-cf68cf30343e'.\n",
      "INFO:mem0.memory.main:{'id': '1', 'text': 'Particularly likes green tea', 'event': 'ADD'}\n",
      "INFO:mem0.vector_stores.mongodb:Inserting 1 vectors into collection 'extracted_memories'.\n",
      "INFO:mem0.vector_stores.mongodb:Inserted 1 documents into 'extracted_memories'.\n",
      "INFO:mem0.vector_stores.mongodb:Retrieved document with ID '2a50db03-70cb-4ce8-85ce-cf68cf30343e'.\n",
      "INFO:mem0.vector_stores.mongodb:Retrieved document with ID '2a50db03-70cb-4ce8-85ce-cf68cf30343e'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: That's great! Green tea is known for its numerous health benefits, including being high in antioxidants and potentially boosting metabolism. Do you have a favorite type of green tea or a particular brand that you enjoy?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mem0.vector_stores.mongodb:Retrieved document with ID '2a50db03-70cb-4ce8-85ce-cf68cf30343e'.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:mem0.vector_stores.mongodb:Vector search completed. Found 2 documents.\n",
      "INFO:mem0.vector_stores.mongodb:Retrieved document with ID '2a50db03-70cb-4ce8-85ce-cf68cf30343e'.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:mem0.vector_stores.mongodb:Vector search completed. Found 3 documents.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memories:\n",
      "- Particularly likes green tea\n",
      "- Likes to drink tea\n",
      "Semantic Memories:\n",
      "- In a narrow sense, the memory of the agent is only relevant to the historical information within\n",
      "the same trial. Formally, for a given task, the historical information of the trial before step t is\n",
      "Œæt = {a1, o1, a2, o2, ..., at‚àí1, ot‚àí1}, and then the memory is derived based on Œæt. In the above toy\n",
      "example, for task (A), the agent at [step 3] needs to arrange the visiting order for Alice; at this time,\n",
      "its memory contains the information about the selected attractions and arrival time in [step 1] and\n",
      "[step 2]. For task (B), the agent has to choose a movie for Alice at [step 3]; at this time, its memory\n",
      "contains the arranged time to watch films.\n",
      "3.3 Broad Definition of the Agent Memory\n",
      "In a broad sense, the memory of the agent can come from much wider sources, for example,\n",
      "the information across different trials and the external knowledge beyond the agent-environment\n",
      "interactions. Formally, given a series of sequential tasks {T1, T2, ...,TK}, for task Tk, the memory\n",
      "- the agent. The second and third ones show that the memory is necessary for the agent‚Äôs evolving\n",
      "principles and applications, which provide insights for designing agents with memory mechanisms.\n",
      "5 How to Implement the Memory of LLM-based Agent\n",
      "In this section, we discuss the implementation of the memory module from three perspectives: memory\n",
      "sources, memory forms, and memory operations. Memory sources refer to where the memory contents\n",
      "come from. Memory forms focus on how to represent the memory contents. Memory operations\n",
      "aim to process the memory contents. These three perspectives provide a comprehensive review of\n",
      "memory implementation methods, which is helpful for future research. For better demonstration, we\n",
      "present an overview of implementation methods in Figure 4.\n",
      "5.1 Memory Sources\n",
      "In previous works, the memory contents may come from different sources. Based on our formulation\n",
      "- information from the environment, and stores it into the memory; (2) the agent processes the stored\n",
      "information to make it more usable; and (3) the agent takes the next action based on the processed\n",
      "memory information. In all these phases, memory plays an extremely important role. In the following,\n",
      "we first define the memory of the agent from both narrow and broad perspectives, and then, detail the\n",
      "execution processes of the above three phases based on the memory module.\n",
      "3.1 Basic Knowledge\n",
      "For clear presentations, we first introduce several important background knowledge as follows:\n",
      "Definition 1 (Task). Task is the final target that the agent needs to achieve, for example, booking a\n",
      "flight ticket for Alice, recommending a restaurant for Bob, and so on. Formally, we useT to represent\n",
      "a task and label different tasks by subscripts in the following contents.\n",
      "Definition 2 (Environment). In a narrow sense, environment is the object that the agent needs to\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:mem0.memory.main:Total existing memories: 0\n",
      "INFO:mem0.vector_stores.mongodb:Retrieved document with ID '2a50db03-70cb-4ce8-85ce-cf68cf30343e'.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AI: The definition of Agent Memory from the paper can be summarized as follows:\n",
      "\n",
      "1. **Narrow Definition**: The memory of the agent is relevant to historical information within the same trial. For a given task, the memory is derived from the sequence of actions and observations before the current step.\n",
      "\n",
      "2. **Broad Definition**: The memory can come from a wider range of sources, including information across different trials and external knowledge beyond the agent-environment interactions. This broader perspective emphasizes the importance of memory for the agent's evolving principles and applications.\n",
      "\n",
      "These definitions highlight the role of memory in the agent's decision-making process and its capacity to learn from past experiences.\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def chat_with_memories(message: str, user_id: str = \"default_user\") -> str:\n",
    "    \"\"\"\n",
    "    Chat function that retrieves relevant memories and generates responses.\n",
    "    \n",
    "    Args:\n",
    "        message (str): User's input message\n",
    "        user_id (str): User identifier for memory retrieval\n",
    "        \n",
    "    Returns:\n",
    "        str: Assistant's response based on memories and query\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Retrieve relevant memories using the fixed search method\n",
    "        relevant_memories = memory.search(query=message, user_id=user_id, limit=3)\n",
    "        relevant_memories_from_semantic_memory = semantic_memory.search(query=message, user_id=user_id, limit=3)\n",
    "        \n",
    "        # Format memories for display and context\n",
    "        memories_str = \"\\n\".join(f\"- {entry['memory']}\" for entry in relevant_memories[\"results\"])\n",
    "        memories_str_from_semantic_memory = \"\\n\".join(f\"- {entry['memory']}\" for entry in relevant_memories_from_semantic_memory[\"results\"])\n",
    "        print(\"Memories:\")\n",
    "        print(memories_str if memories_str else \"No relevant memories found.\")\n",
    "        print(\"Semantic Memories:\")\n",
    "        print(memories_str_from_semantic_memory if memories_str_from_semantic_memory else \"No relevant semantic memories found.\")\n",
    "\n",
    "        # Generate Assistant response with memory context\n",
    "        system_prompt = f\"You are a helpful AI. Answer the question based on the query and memories.\\nUser Memories:\\n{memories_str}\\nSemantic Memories:\\n{memories_str_from_semantic_memory}\"\n",
    "        messages = [{\"role\": \"system\", \"content\": system_prompt}, {\"role\": \"user\", \"content\": message}]\n",
    "        \n",
    "        response = openai_client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "        assistant_response = response.choices[0].message.content\n",
    "\n",
    "        # Create new memories from the conversation\n",
    "        messages.append({\"role\": \"assistant\", \"content\": assistant_response})\n",
    "        memory.add(messages, user_id=user_id)\n",
    "\n",
    "        return assistant_response\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error in chat_with_memories: {e}\")\n",
    "        # Fallback response without memory\n",
    "        messages = [{\"role\": \"user\", \"content\": message}]\n",
    "        response = openai_client.chat.completions.create(model=\"gpt-4o-mini\", messages=messages)\n",
    "        return response.choices[0].message.content\n",
    "\n",
    "def main():\n",
    "    \"\"\"Interactive chat loop\"\"\"\n",
    "    print(\"Chat with AI (type 'exit' to quit)\")\n",
    "    print(\"This AI has memory and can remember your conversation!\")\n",
    "    \n",
    "    while True:\n",
    "        user_input = input(\"\\nYou: \").strip()\n",
    "        if user_input.lower() == 'exit':\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "        \n",
    "        try:\n",
    "            response = chat_with_memories(user_input)\n",
    "            print(f\"AI: {response}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c521daa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mem0.vector_stores.mongodb:Retrieved document with ID '2a50db03-70cb-4ce8-85ce-cf68cf30343e'.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:mem0.vector_stores.mongodb:Vector search completed. Found 2 documents.\n"
     ]
    }
   ],
   "source": [
    "coffee_search = memory.search(query=\"coffee brewing methods and preferences\", user_id=CURRENT_USER_ID, limit=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e79a22cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'results': [{'created_at': None,\n",
       "   'agent_id': None,\n",
       "   'updated_at': None,\n",
       "   'id': '9d520037-eff0-48fe-9cb3-ecc949765cd0',\n",
       "   'user_id': 'default_user',\n",
       "   'actor_id': None,\n",
       "   'run_id': None,\n",
       "   'hash': None,\n",
       "   'role': None,\n",
       "   'data': 'Likes to drink tea',\n",
       "   'score': 0.7095835208892822,\n",
       "   'memory': 'Likes to drink tea',\n",
       "   'metadata': {}},\n",
       "  {'created_at': None,\n",
       "   'agent_id': None,\n",
       "   'updated_at': None,\n",
       "   'id': '21d8fc88-a9bc-423d-8632-c0cd6c893c14',\n",
       "   'user_id': 'default_user',\n",
       "   'actor_id': None,\n",
       "   'run_id': None,\n",
       "   'hash': None,\n",
       "   'role': None,\n",
       "   'data': 'Particularly likes green tea',\n",
       "   'score': 0.681547999382019,\n",
       "   'memory': 'Particularly likes green tea',\n",
       "   'metadata': {}}]}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "coffee_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "49ebb327",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:mem0.vector_stores.mongodb:Retrieved document with ID '2a50db03-70cb-4ce8-85ce-cf68cf30343e'.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
      "INFO:mem0.vector_stores.mongodb:Vector search completed. Found 5 documents.\n"
     ]
    }
   ],
   "source": [
    "paper_search = semantic_memory.search(query=\"What is the main idea of the paper?\", user_id=CURRENT_USER_ID, limit=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c400608e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'results': [{'created_at': None,\n",
       "   'agent_id': None,\n",
       "   'updated_at': None,\n",
       "   'id': '57fd4245-ddb0-4f05-be2b-eb4b08ea08ce',\n",
       "   'user_id': 'user-123',\n",
       "   'actor_id': None,\n",
       "   'run_id': None,\n",
       "   'hash': None,\n",
       "   'role': 'user',\n",
       "   'data': 'LLMs\\n[70‚Äì73]\\nChallenges\\nSecurity\\nYao et al. [64], Shayegani et al.\\n[65], Neel and Chang [66], Smith et al.\\n[67], Dong et al. [68], Das et al. [69].\\nExplainability Zhao et al. [63].\\nBias & Fairness Gallegos et al. [60], Kotek\\net al. [61], Li et al. [62].\\nHallucination\\nZhang et al. [53], Huang et al.\\n[54], Rawte et al. [55], Ye\\net al. [56], Ji et al. [57], Ton-\\nmoy et al. [58], Jiang et al. [59].\\nApplications\\nRecommendation Li et al. [50], Lin et al.\\n[51], Wang et al. [52].\\nPsychology He et al. [49].\\nFinance Li et al. [48].\\nMedecine He et al. [45], Zhou et al.\\n[46], Wang et al. [47].\\nAutonomous Driving Cui et al. [43], Yang et al. [44].\\nRobotics Zeng et al. [42].\\nSoftware Engineering Fan et al. [39], Wang et al.\\n[40], Zheng et al. [41].\\nInformation Processing Yang et al. [36], Zhu\\net al. [37], Xu et al. [38].\\nEvaluation Chang et al. [34], Guo et al. [35].\\nFundamental Problems\\nEfficiency\\nBai et al. [26], Wan et al. [27], Miao\\net al. [28, 28], Xu et al. [29], Zhu',\n",
       "   'score': 0.657835841178894,\n",
       "   'memory': 'LLMs\\n[70‚Äì73]\\nChallenges\\nSecurity\\nYao et al. [64], Shayegani et al.\\n[65], Neel and Chang [66], Smith et al.\\n[67], Dong et al. [68], Das et al. [69].\\nExplainability Zhao et al. [63].\\nBias & Fairness Gallegos et al. [60], Kotek\\net al. [61], Li et al. [62].\\nHallucination\\nZhang et al. [53], Huang et al.\\n[54], Rawte et al. [55], Ye\\net al. [56], Ji et al. [57], Ton-\\nmoy et al. [58], Jiang et al. [59].\\nApplications\\nRecommendation Li et al. [50], Lin et al.\\n[51], Wang et al. [52].\\nPsychology He et al. [49].\\nFinance Li et al. [48].\\nMedecine He et al. [45], Zhou et al.\\n[46], Wang et al. [47].\\nAutonomous Driving Cui et al. [43], Yang et al. [44].\\nRobotics Zeng et al. [42].\\nSoftware Engineering Fan et al. [39], Wang et al.\\n[40], Zheng et al. [41].\\nInformation Processing Yang et al. [36], Zhu\\net al. [37], Xu et al. [38].\\nEvaluation Chang et al. [34], Guo et al. [35].\\nFundamental Problems\\nEfficiency\\nBai et al. [26], Wan et al. [27], Miao\\net al. [28, 28], Xu et al. [29], Zhu',\n",
       "   'metadata': {}},\n",
       "  {'created_at': None,\n",
       "   'agent_id': None,\n",
       "   'updated_at': None,\n",
       "   'id': '3c68b0ea-52bd-4c36-9dd2-4fdc5bb7200c',\n",
       "   'user_id': 'user-123',\n",
       "   'actor_id': None,\n",
       "   'run_id': None,\n",
       "   'hash': None,\n",
       "   'role': 'user',\n",
       "   'data': 'informative knowledge to support its actions, and so on. Around the memory module, people have\\ndevoted much effort to designing its information sources, storage forms, and operation mechanisms.\\nFor example, Shinn et al. [5] incorporate both in-trial and cross-trial information to build the memory\\nmodule for enhancing the agent‚Äôs reasoning capability. Zhong et al. [6] store memory information in\\nthe form of natural languages, which is explainable and friendly to the users. Modarressi et al. [7]\\ndesign both memory reading and writing operations to interact with environments for task solving.\\nWhile previous studies have designed many promising memory modules, there still lacks a systemic\\nstudy to view the memory modules from a holistic perspective. To bridge this gap, in this paper,\\nwe comprehensively review previous studies to present clear taxonomies and key principles for\\ndesigning and evaluating the memory module. In specific, we discuss three key problems including:',\n",
       "   'score': 0.6530595421791077,\n",
       "   'memory': 'informative knowledge to support its actions, and so on. Around the memory module, people have\\ndevoted much effort to designing its information sources, storage forms, and operation mechanisms.\\nFor example, Shinn et al. [5] incorporate both in-trial and cross-trial information to build the memory\\nmodule for enhancing the agent‚Äôs reasoning capability. Zhong et al. [6] store memory information in\\nthe form of natural languages, which is explainable and friendly to the users. Modarressi et al. [7]\\ndesign both memory reading and writing operations to interact with environments for task solving.\\nWhile previous studies have designed many promising memory modules, there still lacks a systemic\\nstudy to view the memory modules from a holistic perspective. To bridge this gap, in this paper,\\nwe comprehensively review previous studies to present clear taxonomies and key principles for\\ndesigning and evaluating the memory module. In specific, we discuss three key problems including:',\n",
       "   'metadata': {}},\n",
       "  {'created_at': None,\n",
       "   'agent_id': None,\n",
       "   'updated_at': None,\n",
       "   'id': '0210cca4-00a2-44d5-9a80-13a3f985be58',\n",
       "   'user_id': 'user-123',\n",
       "   'actor_id': None,\n",
       "   'run_id': None,\n",
       "   'hash': None,\n",
       "   'role': 'user',\n",
       "   'data': 'be stored in the same group. In SCM [98], it designs a memory controller to decide when to execute\\nthe operations. The controller serves as a guide for the whole memory module. In MemGPT [100],\\nthe memory writing is entirely self-directed. The agents can autonomously update the memory based\\non the contexts. In MemoChat [94], the agents summarize each conversation segment by abstracting\\nthe mainly discussed topics and storing them as keys for indexing memory pieces.\\nDiscussion. Previous research indicates that designing the strategy of information extraction during\\nthe memory writing operation is vital [94]. This is because the original information is commonly\\nlengthy and noisy. Besides, different environments may provide various forms of feedback, and how\\nto extract and represent the information as memory is also significant for memory writing.\\n5.3.2 Memory Management\\nFor human beings, memory information is constantly processed and abstracted in the brains. The',\n",
       "   'score': 0.6467303037643433,\n",
       "   'memory': 'be stored in the same group. In SCM [98], it designs a memory controller to decide when to execute\\nthe operations. The controller serves as a guide for the whole memory module. In MemGPT [100],\\nthe memory writing is entirely self-directed. The agents can autonomously update the memory based\\non the contexts. In MemoChat [94], the agents summarize each conversation segment by abstracting\\nthe mainly discussed topics and storing them as keys for indexing memory pieces.\\nDiscussion. Previous research indicates that designing the strategy of information extraction during\\nthe memory writing operation is vital [94]. This is because the original information is commonly\\nlengthy and noisy. Besides, different environments may provide various forms of feedback, and how\\nto extract and represent the information as memory is also significant for memory writing.\\n5.3.2 Memory Management\\nFor human beings, memory information is constantly processed and abstracted in the brains. The',\n",
       "   'metadata': {}},\n",
       "  {'created_at': None,\n",
       "   'agent_id': None,\n",
       "   'updated_at': None,\n",
       "   'id': '4ded0cf4-5af3-4b68-85dd-ddd12a474fe6',\n",
       "   'user_id': 'user-123',\n",
       "   'actor_id': None,\n",
       "   'run_id': None,\n",
       "   'hash': None,\n",
       "   'role': 'user',\n",
       "   'data': 'We separate the entire procedure of memory into three operations: memory writing, memory manage-\\nment, and memory reading. These three typically collaborate to achieve memory function, providing\\ninformation for LLM inference. We summarize previous works on memory operations in Table 3.\\n5.3.1 Memory Writing\\nAfter the information is perceived by the agent, a part of it will be stored by the agent for further usage\\nthrough the memory writing operation, and it is crucial to recognize which information is essential to\\nstore. Many studies choose to store the raw information, while others also put the summary of the\\nraw information into the memory module.\\nRepresentative Studies. In TiM [97], the raw information will be extracted as the relation between\\ntwo entities, and stored in a structured database. When writing into the database, similar contents will\\nbe stored in the same group. In SCM [98], it designs a memory controller to decide when to execute',\n",
       "   'score': 0.6453251242637634,\n",
       "   'memory': 'We separate the entire procedure of memory into three operations: memory writing, memory manage-\\nment, and memory reading. These three typically collaborate to achieve memory function, providing\\ninformation for LLM inference. We summarize previous works on memory operations in Table 3.\\n5.3.1 Memory Writing\\nAfter the information is perceived by the agent, a part of it will be stored by the agent for further usage\\nthrough the memory writing operation, and it is crucial to recognize which information is essential to\\nstore. Many studies choose to store the raw information, while others also put the summary of the\\nraw information into the memory module.\\nRepresentative Studies. In TiM [97], the raw information will be extracted as the relation between\\ntwo entities, and stored in a structured database. When writing into the database, similar contents will\\nbe stored in the same group. In SCM [98], it designs a memory controller to decide when to execute',\n",
       "   'metadata': {}},\n",
       "  {'created_at': None,\n",
       "   'agent_id': None,\n",
       "   'updated_at': None,\n",
       "   'id': 'df668189-0829-44d5-9a30-9368f8ca48f8',\n",
       "   'user_id': 'user-123',\n",
       "   'actor_id': None,\n",
       "   'run_id': None,\n",
       "   'hash': None,\n",
       "   'role': 'user',\n",
       "   'data': 'we comprehensively review previous studies to present clear taxonomies and key principles for\\ndesigning and evaluating the memory module. In specific, we discuss three key problems including:\\n(1) what is the memory of LLM-based agents? (2) why do we need the memory in LLM-based\\nagents? and (3) how to implement and evaluate the memory in LLM-based agents? To begin with,\\nwe detail the concepts of memory in LLM-based agents, providing both narrow and broad definitions.\\nThen, we analyze the necessity of memory in LLM-based agents, showing its importance from\\nthree perspectives including cognitive psychology, self-evolution, and agent applications. Based on\\nthe problems of ‚Äúwhat‚Äù and ‚Äúwhy‚Äù, we present commonly used strategies to design and evaluate\\nthe memory modules. For the memory design, we discuss previous works from three dimensions,\\nthat is, memory sources, memory forms, and memory operations. For the memory evaluation, we',\n",
       "   'score': 0.6431492567062378,\n",
       "   'memory': 'we comprehensively review previous studies to present clear taxonomies and key principles for\\ndesigning and evaluating the memory module. In specific, we discuss three key problems including:\\n(1) what is the memory of LLM-based agents? (2) why do we need the memory in LLM-based\\nagents? and (3) how to implement and evaluate the memory in LLM-based agents? To begin with,\\nwe detail the concepts of memory in LLM-based agents, providing both narrow and broad definitions.\\nThen, we analyze the necessity of memory in LLM-based agents, showing its importance from\\nthree perspectives including cognitive psychology, self-evolution, and agent applications. Based on\\nthe problems of ‚Äúwhat‚Äù and ‚Äúwhy‚Äù, we present commonly used strategies to design and evaluate\\nthe memory modules. For the memory design, we discuss previous works from three dimensions,\\nthat is, memory sources, memory forms, and memory operations. For the memory evaluation, we',\n",
       "   'metadata': {}}]}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paper_search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36152685",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_memory_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
