{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c5913660",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github.com/RichmondAlake/agent_memory_course/blob/main/memory_bank/memory_augmented_agent_with_local_memory.ipynb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9762d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install -qU google-adk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8a865ed9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/richmondalake/miniconda3/envs/agent_memory_course/lib/python3.11/site-packages/pydantic/_internal/_fields.py:198: UserWarning: Field name \"config_type\" in \"SequentialAgent\" shadows an attribute in parent \"BaseAgent\"\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.sessions import InMemorySessionService, Session\n",
    "from google.adk.artifacts import InMemoryArtifactService\n",
    "from google.adk.memory import InMemoryMemoryService \n",
    "from google.adk.runners import Runner\n",
    "from google.adk.tools import load_memory\n",
    "from google.genai.types import Content, Part\n",
    "from google.adk.tools.tool_context import ToolContext\n",
    "from google.adk.tools import FunctionTool\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4120c37d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Constants ---\n",
    "APP_NAME = \"memory_example_app\"\n",
    "USER_ID = \"mem_user\"\n",
    "MODEL = \"gemini-2.0-flash\" # Use a valid model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57ea04a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "\n",
    "# Function to securely get and set environment variables\n",
    "def set_env_securely(var_name, prompt):\n",
    "    value = getpass.getpass(prompt)\n",
    "    os.environ[var_name] = value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd72f4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_env_securely(\"GOOGLE_API_KEY\", \"Enter your GOOGLE_API_KEY: \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3f274f9",
   "metadata": {},
   "source": [
    "## Data Ingestion and Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "402b00b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading PDF from https://arxiv.org/pdf/2404.13501...\n",
      "Loading PDF with LangChain...\n",
      "Chunking text...\n",
      "Successfully created 197 chunks\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "# Method 1: Add the project root directory to Python path\n",
    "project_root = \"/Users/richmondalake/Desktop/Projects/open_source/agent_memory_course\"\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from utilities.pdf_chunker import ingest_pdf_and_chunk\n",
    "\n",
    "url = \"https://arxiv.org/pdf/2404.13501\"\n",
    "\n",
    "# Ingest and chunk the PDF\n",
    "chunks = ingest_pdf_and_chunk(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd20174c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Services ---\n",
    "# Services must be shared across runners to share state and memory\n",
    "# Use in-memory for demo\n",
    "session_service = InMemorySessionService()\n",
    "memory_service = InMemoryMemoryService() \n",
    "artifact_service = InMemoryArtifactService()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "97204bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pdf_query_tool_with_chunks(pdf_chunks):\n",
    "    \"\"\"Create a PDF query tool with access to the chunks.\"\"\"\n",
    "    \n",
    "    def pdf_query_func(query: str) -> str:\n",
    "        \"\"\"Query PDF content.\"\"\"\n",
    "        try:\n",
    "            if not pdf_chunks:\n",
    "                return \"No PDF content available.\"\n",
    "            \n",
    "            # Search through chunks\n",
    "            relevant_chunks = []\n",
    "            query_lower = query.lower()\n",
    "            \n",
    "            for chunk in pdf_chunks:\n",
    "                content = chunk['value']['content'].lower()\n",
    "                if any(term in content for term in query_lower.split()):\n",
    "                    relevant_chunks.append(chunk['value']['content'])\n",
    "            \n",
    "            if relevant_chunks:\n",
    "                result = \"\\n\\n\".join(relevant_chunks[:3])\n",
    "                return f\"Found relevant PDF content:\\n\\n{result}\"\n",
    "            else:\n",
    "                return f\"No relevant content found for: {query}\"\n",
    "                \n",
    "        except Exception as e:\n",
    "            return f\"Error searching PDF: {str(e)}\"\n",
    "    \n",
    "    return FunctionTool(func=pdf_query_func)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cc4adc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Create the PDF query tool with your chunks\n",
    "pdf_query_tool = create_pdf_query_tool_with_chunks(chunks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "13108338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the agent to use the corrected tool\n",
    "pdf_memory_agent = LlmAgent(\n",
    "    model=MODEL,\n",
    "    name=\"PDFMemoryAgent\",\n",
    "    instruction=\"You are an AI assistant that can query PDF content and use memory. \"\n",
    "                \"Use the 'pdf_query_func' to search through PDF content. \"\n",
    "                \"Use the 'load_memory' tool to recall past conversations. \"\n",
    "                \"When a user asks about PDF content, use the pdf_query_func tool.\",\n",
    "    tools=[load_memory, pdf_query_tool]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "11235e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_pdf_scenario():\n",
    "    \"\"\"Run scenario with three specific questions about the paper.\"\"\"\n",
    "    \n",
    "    # Create runner\n",
    "    runner = Runner(\n",
    "        agent=pdf_memory_agent,\n",
    "        app_name=APP_NAME,\n",
    "        session_service=session_service,\n",
    "        memory_service=memory_service,\n",
    "        artifact_service=artifact_service\n",
    "    )\n",
    "    \n",
    "    # Create session for querying\n",
    "    session_id = \"pdf_query_session\"\n",
    "    await runner.session_service.create_session(\n",
    "        app_name=APP_NAME, \n",
    "        user_id=USER_ID, \n",
    "        session_id=session_id\n",
    "    )\n",
    "    \n",
    "    # Define three questions about the paper\n",
    "    questions = [\n",
    "        \"What is the main contribution and purpose of this research paper?\",\n",
    "        \"What methodology or approach does the paper use for their experiments?\",\n",
    "        \"What are the key findings and results presented in this paper?\"\n",
    "    ]\n",
    "    \n",
    "    # Ask each question and collect responses\n",
    "    for i, question in enumerate(questions, 1):\n",
    "        print(f\"\\n--- Question {i}: {question} ---\")\n",
    "        \n",
    "        query_input = Content(\n",
    "            parts=[Part(text=question)], \n",
    "            role=\"user\"\n",
    "        )\n",
    "        \n",
    "        async for event in runner.run_async(\n",
    "            user_id=USER_ID, \n",
    "            session_id=session_id, \n",
    "            new_message=query_input\n",
    "        ):\n",
    "            if event.is_final_response() and event.content and event.content.parts:\n",
    "                print(f\"Answer {i}: {event.content.parts[0].text}\")\n",
    "                print(\"-\" * 80)\n",
    "    \n",
    "    # Add this session to memory for future recall\n",
    "    completed_session = await runner.session_service.get_session(\n",
    "        app_name=APP_NAME, user_id=USER_ID, session_id=session_id\n",
    "    )\n",
    "    await memory_service.add_session_to_memory(completed_session)\n",
    "    print(\"\\nâœ“ Session added to memory for future recall.\")\n",
    "    \n",
    "    # Test memory recall in a new session\n",
    "    print(\"\\n--- Testing Memory Recall ---\")\n",
    "    memory_session_id = \"memory_test_session\"\n",
    "    await runner.session_service.create_session(\n",
    "        app_name=APP_NAME, \n",
    "        user_id=USER_ID, \n",
    "        session_id=memory_session_id\n",
    "    )\n",
    "    \n",
    "    memory_query = Content(\n",
    "        parts=[Part(text=\"Can you summarize what we discussed about the research paper's main contributions?\")], \n",
    "        role=\"user\"\n",
    "    )\n",
    "    \n",
    "    async for event in runner.run_async(\n",
    "        user_id=USER_ID, \n",
    "        session_id=memory_session_id, \n",
    "        new_message=memory_query\n",
    "    ):\n",
    "        if event.is_final_response() and event.content and event.content.parts:\n",
    "            print(f\"Memory Recall Response: {event.content.parts[0].text}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2741b4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Question 1: What is the main contribution and purpose of this research paper? ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 1: The paper is a comprehensive survey on the memory mechanisms of Large Language Model (LLM) based agents. It addresses the gap in the existing literature by providing a systematic review, summarizing and comparing different memory mechanisms, and abstracting common design patterns. The purpose is to discuss the \"what\" and \"why\" of memory in LLM-based agents, review studies on designing and evaluating memory modules, present agent applications, analyze limitations, and suggest future directions.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Question 2: What methodology or approach does the paper use for their experiments? ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 2: The paper is a survey, so the methodology involves a systematic review of existing studies on memory mechanisms in LLM-based agents. The approach includes identifying, categorizing, and comparing different memory designs and evaluation methods used in previous research. They also analyze applications of these memory modules and discuss limitations and future research directions based on the reviewed literature.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "--- Question 3: What are the key findings and results presented in this paper? ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer 3: Since this is a survey paper, the key findings and results are a synthesis of the existing literature. The paper likely identifies common and effective design patterns for memory mechanisms in LLM-based agents, summarizes different approaches to designing and evaluating memory modules, highlights the role of memory in various agent applications, and points out the limitations of current memory mechanisms, suggesting potential future research directions.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "âœ“ Session added to memory for future recall.\n",
      "\n",
      "--- Testing Memory Recall ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory Recall Response: The paper is a survey that provides a systematic review of memory mechanisms in Large Language Model (LLM) based agents. It summarizes and compares different memory mechanisms, abstracts common design patterns, discusses the \"what\" and \"why\" of memory in LLM-based agents, reviews studies on designing and evaluating memory modules, presents agent applications, analyzes limitations, and suggests future directions. The key findings are a synthesis of existing literature, identifying effective design patterns, summarizing approaches to memory module design and evaluation, highlighting the role of memory in applications, and suggesting future research directions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Run the PDF scenario with three questions\n",
    "await run_pdf_scenario()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37712c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent_memory_course",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
